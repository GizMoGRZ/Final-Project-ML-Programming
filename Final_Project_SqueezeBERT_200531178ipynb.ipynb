{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch sentencepiece evaluate lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZMAdZYGzfqa",
        "outputId": "a2ef1e9b-e9de-4005-c51e-f7da61d59d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6XrcPc2SCkj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "from lxml import etree\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    SqueezeBertTokenizer,\n",
        "    SqueezeBertForMaskedLM,\n",
        "    SqueezeBertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg3QjtuHTYMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe384ad-0345-4dd7-b9cb-c95aa0155c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking if XML dump exists in Colab directory...\n",
            "\n",
            "Files in /content:\n",
            "File already exists: enwiki-20251201-pages-articles-multistream1.xml-p1p41242\n",
            "No upload needed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The XML file name\n",
        "DUMP_FILE = \"enwiki-20251201-pages-articles-multistream1.xml-p1p41242\"\n",
        "\n",
        "print(\"Checking if XML dump exists in Colab directory...\\n\")\n",
        "\n",
        "# Show directory contents\n",
        "print(\"Files in /content:\")\n",
        "\n",
        "# If the file exists then skip the browse\n",
        "if os.path.exists(DUMP_FILE):\n",
        "    print(f\"File already exists: {DUMP_FILE}\")\n",
        "    print(\"No upload needed.\\n\")\n",
        "\n",
        "else:\n",
        "    print(f\"File '{DUMP_FILE}' not found.\\n\")\n",
        "    print(\"Please upload the XML Wikipedia dump file now.\")\n",
        "\n",
        "    # Ask user to upload\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get uploaded filename\n",
        "    uploaded_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # Rename to match expected filename\n",
        "    if uploaded_filename != DUMP_FILE:\n",
        "        os.rename(uploaded_filename, DUMP_FILE)\n",
        "        print(f\"Renamed '{uploaded_filename}' â†’ '{DUMP_FILE}'\")\n",
        "\n",
        "    print(\"\\nUpload complete! The XML file is ready for processing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-IWIcCmjRAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de87ca2-e013-4cb0-8a14-1d2f01e3c672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 100 articles.\n"
          ]
        }
      ],
      "source": [
        "# Extraxt the info from the XML\n",
        "from lxml import etree\n",
        "\n",
        "DUMP_FILE = \"enwiki-20251201-pages-articles-multistream1.xml-p1p41242\"\n",
        "wiki_texts = []\n",
        "\n",
        "# recover=True allows parsing truncated or malformed XML\n",
        "context = etree.iterparse(DUMP_FILE, events=(\"end\",), tag=\"{http://www.mediawiki.org/xml/export-0.11/}page\", recover=True)\n",
        "\n",
        "for event, elem in context:\n",
        "    text_elem = elem.find(\"{http://www.mediawiki.org/xml/export-0.11/}revision/{http://www.mediawiki.org/xml/export-0.11/}text\")\n",
        "    if text_elem is not None and text_elem.text:\n",
        "        wiki_texts.append(text_elem.text.strip())\n",
        "    elem.clear()\n",
        "    if len(wiki_texts) >= 100:\n",
        "        break  # stop after 1000 articles\n",
        "\n",
        "print(f\"Extracted {len(wiki_texts)} articles.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpEgqr16ScNh"
      },
      "outputs": [],
      "source": [
        "# SqueezeBERT tokenizer\n",
        "sqbert_tokenizer = SqueezeBertTokenizer.from_pretrained('squeezebert/squeezebert-uncased')\n",
        "\n",
        "# BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n0hPGwKSd3Z"
      },
      "outputs": [],
      "source": [
        "# Tokenize Wikipedia texts for MLM\n",
        "tokenized_inputs = sqbert_tokenizer(\n",
        "    wiki_texts,\n",
        "    return_tensors='pt',\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=128\n",
        ")\n",
        "\n",
        "# Create DataCollator for masked language modeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=sqbert_tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# Simple torch dataset wrapper\n",
        "class MLMDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __len__(self):\n",
        "        return self.encodings['input_ids'].size(0)\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "mlm_dataset = MLMDataset(tokenized_inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhXx0Ni-jxVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "e6efcaff-8d57-47a2-ed7b-01e4aed8a14e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:10, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.265600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.684900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load SqueezeBERT for MLM\n",
        "mlm_model = SqueezeBertForMaskedLM.from_pretrained('squeezebert/squeezebert-uncased')\n",
        "\n",
        "# Training arguments for MLM\n",
        "mlm_args = TrainingArguments(\n",
        "    output_dir=\"./mlm_results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=50,\n",
        "    save_total_limit=1,\n",
        "    logging_dir=\"./mlm_logs\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=5e-5\n",
        ")\n",
        "\n",
        "# Trainer for MLM\n",
        "mlm_trainer = Trainer(\n",
        "    model=mlm_model,\n",
        "    args=mlm_args,\n",
        "    train_dataset=mlm_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Train domain-adaptive MLM\n",
        "mlm_trainer.train()\n",
        "mlm_trainer.save_model(\"./squeezebert_mlm_adapted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwvHIeiLkIn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e85883-732e-4ba8-c148-b747b12d5303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data: {'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n"
          ]
        }
      ],
      "source": [
        "# Load the GLUE dataset for benchmarking\n",
        "dataset_name = \"mrpc\"\n",
        "dataset = load_dataset(\"glue\", dataset_name)\n",
        "metric = evaluate.load(\"glue\", dataset_name)\n",
        "\n",
        "print(\"Sample data:\", dataset['train'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjMzZMPeUHEA"
      },
      "outputs": [],
      "source": [
        "def tokenize_pair(examples, tokenizer):\n",
        "    return tokenizer(\n",
        "        examples['sentence1'], examples['sentence2'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# Tokenize for SqueezeBERT\n",
        "encoded_sqbert = dataset.map(lambda x: tokenize_pair(x, sqbert_tokenizer), batched=True)\n",
        "encoded_sqbert = encoded_sqbert.map(lambda x: {'labels': x['label']}, batched=True)\n",
        "encoded_sqbert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Tokenize for BERT\n",
        "encoded_bert = dataset.map(lambda x: tokenize_pair(x, bert_tokenizer), batched=True)\n",
        "encoded_bert = encoded_bert.map(lambda x: {'labels': x['label']}, batched=True)\n",
        "encoded_bert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eaqto_Q8Uo_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2856aa50-6dc8-4a5c-c99c-1fe4984cd208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load vanilla BERT for sequence classification for my significant contribution\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',  # pretrained BERT\n",
        "    num_labels=2          # binary classification for MRPC or similar tasks\n",
        ")\n",
        "\n",
        "# No custom layers added here; this is standard BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMNarXbFU3nv"
      },
      "outputs": [],
      "source": [
        "# Function to define compute evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    # Convert logits to predicted class by argmax\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    # Compute accuracy, F1, or other metrics provided by GLUE\n",
        "    return metric.compute(predictions=predictions, references=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnuitSLTktr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52a4311-d371-4d91-8228-635cb114acb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SqueezeBertForSequenceClassification were not initialized from the model checkpoint at ./squeezebert_mlm_adapted and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SqueezeBertForSequenceClassification were not initialized from the model checkpoint at ./squeezebert_mlm_adapted and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Baseline SqueezeBERT\n",
        "sq_model_base = SqueezeBertForSequenceClassification.from_pretrained(\n",
        "    \"./squeezebert_mlm_adapted\", num_labels=2\n",
        ")\n",
        "\n",
        "# Modified SqueezeBERT (same weights, separate instance)\n",
        "sq_model_mod = SqueezeBertForSequenceClassification.from_pretrained(\n",
        "    \"./squeezebert_mlm_adapted\", num_labels=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LosMxpXLkwSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b48912-a6d6-4339-d7c7-4f097569599a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Creat the base BERT model\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl74O-E-lAZ8"
      },
      "outputs": [],
      "source": [
        "# Baseline SqueezeBERT\n",
        "training_args_sq_base = TrainingArguments(\n",
        "    output_dir=\"./sq_base\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=5e-5,\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    do_eval=True,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Modified SqueezeBERT (different hyperparameters)\n",
        "training_args_sq_mod = TrainingArguments(\n",
        "    output_dir=\"./sq_modified\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=3e-5,\n",
        "    logging_steps=50,\n",
        "    save_steps=200,\n",
        "    eval_steps=200,\n",
        "    weight_decay=0.02,\n",
        "    do_eval=True,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# BERT Training\n",
        "training_args_bert = TrainingArguments(\n",
        "    output_dir=\"./bert_results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    do_eval=True,\n",
        "    fp16=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNnuZ5TGVApB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9edb21d-b152-4e32-86fb-9cce7932a9d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-896346713.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_sq_base = Trainer(\n",
            "/tmp/ipython-input-896346713.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_sq_mod = Trainer(\n",
            "/tmp/ipython-input-896346713.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_bert = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Baseline SqueezeBERT Trainer\n",
        "trainer_sq_base = Trainer(\n",
        "    model=sq_model_base,\n",
        "    args=training_args_sq_base,\n",
        "    train_dataset=encoded_sqbert['train'],\n",
        "    eval_dataset=encoded_sqbert['validation'],\n",
        "    tokenizer=sqbert_tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Modified SqueezeBERT Trainer\n",
        "trainer_sq_mod = Trainer(\n",
        "    model=sq_model_mod,\n",
        "    args=training_args_sq_mod,\n",
        "    train_dataset=encoded_sqbert['train'],\n",
        "    eval_dataset=encoded_sqbert['validation'],\n",
        "    tokenizer=sqbert_tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# BERT Trainer\n",
        "trainer_bert = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args_bert,\n",
        "    train_dataset=encoded_bert['train'],\n",
        "    eval_dataset=encoded_bert['validation'],\n",
        "    tokenizer=bert_tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0ljEUx6VG9M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "1f89e885-0a8d-49a4-a384-7a17575af96b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [690/690 07:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.487700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.344400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.298000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.245900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [460/460 09:56, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.622900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.556600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.503000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.437800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.349500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.348300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.282600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.292800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [690/690 03:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.624100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.535200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.411000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.346300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.332000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.223800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train the SqueezeBERT model\n",
        "trainer_sq_base.train()\n",
        "trainer_sq_base.save_model(\"./sq_base_model\")\n",
        "\n",
        "# Train the Modified SqueezeBERT\n",
        "trainer_sq_mod.train()\n",
        "trainer_sq_mod.save_model(\"./sq_modified_model\")\n",
        "\n",
        "# Train BERT\n",
        "trainer_bert.train()\n",
        "trainer_bert.save_model(\"./bert_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL-V76zCldbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "54494bb4-7646-47c6-ed75-73b5175a7509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline SqueezeBERT Evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3745376765727997, 'eval_accuracy': 0.8651960784313726, 'eval_f1': 0.9046793760831889, 'eval_runtime': 12.0944, 'eval_samples_per_second': 33.735, 'eval_steps_per_second': 2.15, 'epoch': 3.0}\n",
            "\n",
            "Modified SqueezeBERT Evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3677081763744354, 'eval_accuracy': 0.8333333333333334, 'eval_f1': 0.8811188811188811, 'eval_runtime': 11.8983, 'eval_samples_per_second': 34.291, 'eval_steps_per_second': 1.093, 'epoch': 4.0}\n",
            "\n",
            "BERT Evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4333786368370056, 'eval_accuracy': 0.8431372549019608, 'eval_f1': 0.887719298245614, 'eval_runtime': 0.8685, 'eval_samples_per_second': 469.764, 'eval_steps_per_second': 29.936, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# evalute each model based on the research papers GLUE metric\n",
        "print(\"Baseline SqueezeBERT Evaluation:\")\n",
        "print(trainer_sq_base.evaluate())\n",
        "\n",
        "print(\"\\nModified SqueezeBERT Evaluation:\")\n",
        "print(trainer_sq_mod.evaluate())\n",
        "\n",
        "print(\"\\nBERT Evaluation:\")\n",
        "print(trainer_bert.evaluate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "N14beXcAldM3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "38f4d11a-d7c0-410a-f163-f83a04ab879f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SqueezeBERT Base processed 100 sentences in 0.04 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3860650410.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SqueezeBERT Tuned processed 100 sentences in 0.02 seconds\n",
            "BERT processed 100 sentences in 0.01 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Model  Inference Time (s)\n",
              "0   SqueezeBERT Base            0.035624\n",
              "1  SqueezeBERT Tuned            0.021204\n",
              "2               BERT            0.014304"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3713a7f-e6de-4d82-b5d3-481c999f6974\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SqueezeBERT Base</td>\n",
              "      <td>0.035624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SqueezeBERT Tuned</td>\n",
              "      <td>0.021204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BERT</td>\n",
              "      <td>0.014304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3713a7f-e6de-4d82-b5d3-481c999f6974')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3713a7f-e6de-4d82-b5d3-481c999f6974 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3713a7f-e6de-4d82-b5d3-481c999f6974');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-83d1696b-664a-41b7-90bf-aebb53e88e0a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83d1696b-664a-41b7-90bf-aebb53e88e0a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-83d1696b-664a-41b7-90bf-aebb53e88e0a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0268afe4-a2ef-489a-858f-fbcf4d66e0c3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0268afe4-a2ef-489a-858f-fbcf4d66e0c3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SqueezeBERT Base\",\n          \"SqueezeBERT Tuned\",\n          \"BERT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inference Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01087879365526577,\n        \"min\": 0.014304161071777344,\n        \"max\": 0.035624027252197266,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.035624027252197266,\n          0.02120351791381836,\n          0.014304161071777344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Move models to device and use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sq_model_base.to(device)\n",
        "sq_model_mod.to(device)\n",
        "bert_model.to(device)\n",
        "\n",
        "# Sample 100 XML sentences\n",
        "sample_texts = wiki_texts[:100]\n",
        "\n",
        "# Dictionary for tokenizers\n",
        "tokenizers = {\n",
        "    \"SqueezeBERT Base\": sqbert_tokenizer,\n",
        "    \"SqueezeBERT Tuned\": sqbert_tokenizer,\n",
        "    \"BERT\": bert_tokenizer\n",
        "}\n",
        "\n",
        "# Models dictionary\n",
        "models = {\n",
        "    \"SqueezeBERT Base\": sq_model_base,\n",
        "    \"SqueezeBERT Tuned\": sq_model_mod,\n",
        "    \"BERT\": bert_model\n",
        "}\n",
        "\n",
        "# DataFrame to store timing results\n",
        "results_df = pd.DataFrame(columns=[\"Model\", \"Inference Time (s)\"])\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    tokenizer = tokenizers[model_name]\n",
        "    inputs = tokenizer(sample_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    end_time = time.time()\n",
        "\n",
        "    inference_time = end_time - start_time\n",
        "    print(f\"{model_name} processed 100 sentences in {inference_time:.2f} seconds\")\n",
        "\n",
        "    results_df = pd.concat([results_df, pd.DataFrame({\n",
        "        \"Model\": [model_name],\n",
        "        \"Inference Time (s)\": [inference_time]\n",
        "    })])\n",
        "\n",
        "results_df.reset_index(drop=True, inplace=True)\n",
        "results_df\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}